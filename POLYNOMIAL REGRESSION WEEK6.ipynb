{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3183c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from random import seed\n",
    "from random import randrange\n",
    "# importing StandardScaler library        \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fe1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegression:\n",
    "    def __init__(self, degree=2, lr=0.001, n_iters=1000):\n",
    "        self.degree = degree\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.scaler = None\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # Add polynomial features\n",
    "        X_poly = self._polynomial_features(X, self.degree)\n",
    "\n",
    "        # Normalize data\n",
    "        self.scaler = StandardScaler()\n",
    "        X_poly = self.scaler.fit_transform(X_poly)\n",
    "\n",
    "        n_samples, n_features = X_poly.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = np.dot(X_poly, self.weights) + self.bias\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X_poly.T, (y_pred - y))\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights = self.weights - self.lr * dw\n",
    "            self.bias = self.bias - self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add polynomial features\n",
    "        X_poly = self._polynomial_features(X, self.degree)\n",
    "\n",
    "        # Normalize data\n",
    "        X_poly = self.scaler.transform(X_poly)\n",
    "\n",
    "        y_pred = np.dot(X_poly, self.weights) + self.bias\n",
    "        return y_pred\n",
    "\n",
    "    def _polynomial_features(self, X, degree):\n",
    "        n_samples, n_features = X.shape\n",
    "        X_poly = np.ones((n_samples, 1))\n",
    "\n",
    "        for d in range(1, degree+1):\n",
    "            for i in range(n_features):\n",
    "                X_poly = np.concatenate((X_poly, (X[:,i]**d).reshape(-1,1)), axis=1)\n",
    "\n",
    "        return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1806a4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagendra Swamy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#d = datasets.load_boston()\n",
    "#x, y = d.data, d.target\n",
    "\n",
    "# Load Boston dataset\n",
    "boston = datasets.load_boston()\n",
    "X, y = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1139c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e3e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model and make predictions\n",
    "reg = PolynomialRegression(degree=2, lr=0.1, n_iters=1000)\n",
    "reg.fit(X_train, y_train)\n",
    "predictions = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e45e1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.8536406806101906\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "r2score = r2_score(y_test, predictions)\n",
    "print('R2 score:', r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b0537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutsklearn=round(r2score, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35eb59a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withoutsklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee9b1ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagendra Swamy\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\Nagendra Swamy\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\Nagendra Swamy\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: (0.001, 1000, 2)\n",
      "Validation r2score: 0.8536406806101906\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# define hyperparameters to tune\n",
    "lr = [0.001, 0.1, 0.5]\n",
    "n_iters = [1000, 5000, 10000]\n",
    "degree = [2, 3]\n",
    "\n",
    "# create all possible combinations of hyperparameters\n",
    "hyperparameters = list(product(lr, n_iters,degree))\n",
    "\n",
    "# initialize best accuracy and corresponding hyperparameters\n",
    "best_r2score = 0\n",
    "best_hyperparameters = None\n",
    "\n",
    "# loop over all hyperparameters\n",
    "for hyperparameter in hyperparameters:\n",
    "    # create a new instance of LinearRegression with the current hyperparameters\n",
    "    lr = PolynomialRegression(lr=hyperparameter[0], n_iters=hyperparameter[1], degree=hyperparameter[2])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1234)\n",
    "    \n",
    "    # fit the model\n",
    "    lr.fit(X_train, y_train)\n",
    " \n",
    "    \n",
    "    # evaluate the model on the validation set\n",
    "    y_pred = lr.predict(X_test)\n",
    "    r2score=r2_score(y_test, predictions)\n",
    "    \n",
    "    # update best accuracy and corresponding hyperparameters\n",
    "    if r2score > best_r2score:\n",
    "        best_r2score= r2score\n",
    "        best_hyperparameters = hyperparameter\n",
    "        \n",
    "# print the best hyperparameters and corresponding accuracy\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)\n",
    "print(\"Validation r2score:\", best_r2score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3bd7f",
   "metadata": {},
   "source": [
    "# Model using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48a94b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbaff89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Nagendra Swamy/Desktop/6000/HousingData.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d3f8d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       20\n",
       "ZN         20\n",
       "INDUS      20\n",
       "CHAS       20\n",
       "NOX         0\n",
       "RM          0\n",
       "AGE        20\n",
       "DIS         0\n",
       "RAD         0\n",
       "TAX         0\n",
       "PTRATIO     0\n",
       "B           0\n",
       "LSTAT      20\n",
       "MEDV        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a423b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>11.43</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>11.43</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>76.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  76.8  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90  11.43  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99  11.43  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(df.median())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "190f6d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa9cdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 4)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(np.c_[df['LSTAT'], df['RM'], df['CRIM'], df['NOX']], columns=['LSTAT', 'RM', 'CRIM', 'NOX'])\n",
    "Y = df['MEDV']\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0018dd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 4)\n",
      "(127, 4)\n",
      "(379,)\n",
      "(127,)\n"
     ]
    }
   ],
   "source": [
    "# splits the training and test data set in 75% : 25%\n",
    "# assign random_state to any value.This ensures consistency.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c2053bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression coefficients: [-0.56649976  5.35239531 -0.13861706 -0.60246748]\n",
      "Linear Regression intercept: -3.1562012904884504\n"
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "print('Linear Regression coefficients: {}'.format(lm.coef_))\n",
    "print('Linear Regression intercept: {}'.format(lm.intercept_))\n",
    "\n",
    "# model evaluation for training set\n",
    "y_train_predict = lm.predict(X_train)\n",
    "\n",
    "# plt.plot(np.unique(Y_train), np.poly1d(np.polyfit(Y_train, y_train_predict, 1))(np.unique(Y_train)), \n",
    "#         linewidth=2, color='r')\n",
    "\n",
    "# calculating the intercept and slope for the regression line\n",
    "b, m = np.polynomial.polynomial.polyfit(Y_train, y_train_predict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca14780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The linear model performance for training set\n",
      "RMSE is 5.542915517308062\n",
      "R2 score is 0.6384156083074264\n"
     ]
    }
   ],
   "source": [
    "rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
    "r2 = r2_score(Y_train, y_train_predict)\n",
    " \n",
    "print(\"The linear model performance for training set\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22203e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation for testing set\n",
    "y_test_predict = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "880da3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The linear model performance for testing set\n",
      "RMSE is 5.5299665348068725\n",
      "R2 score is 0.6295124547192935\n"
     ]
    }
   ],
   "source": [
    "# root mean square error of the model\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    " \n",
    "# r-squared score of the model\n",
    "r2 = r2_score(Y_test, y_test_predict)\n",
    "\n",
    "print(\"\\nThe linear model performance for testing set\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34760e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Creates a polynomial regression model for the given degree\"\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "   \n",
    "# transform the features to higher degree features.\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "   \n",
    "# fit the transformed features to Linear Regression\n",
    "poly_model = LinearRegression()\n",
    "\n",
    "poly_model.fit(X_train_poly, Y_train)\n",
    "     \n",
    "# predicting on training data-set\n",
    "y_train_predicted = poly_model.predict(X_train_poly)\n",
    "   \n",
    "# predicting on test data-set\n",
    "y_test_predicted = poly_model.predict(poly_features.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cb49985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The polynomial model performance for the training set\n",
      "RMSE of training set is 4.24827458820609\n",
      "R2 score of training set is 0.7875981397531204\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model on training data-set\n",
    "rmse_train = np.sqrt(mean_squared_error(Y_train, y_train_predicted))\n",
    "r2_train = r2_score(Y_train, y_train_predicted)\n",
    "     \n",
    "print(\"The polynomial model performance for the training set\")\n",
    "print(\"RMSE of training set is {}\".format(rmse_train))\n",
    "print(\"R2 score of training set is {}\".format(r2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fcb65b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The polynomial model performance for the test set\n",
      "RMSE of test set is 4.166238351476593\n",
      "R2 score of test set is 0.7897108665470502\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model on test data-set\n",
    "rmse_test = np.sqrt(mean_squared_error(Y_test, y_test_predicted))\n",
    "r2_test = r2_score(Y_test, y_test_predicted)\n",
    "\n",
    "print(\"The polynomial model performance for the test set\")\n",
    "print(\"RMSE of test set is {}\".format(rmse_test))\n",
    "print(\"R2 score of test set is {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57c674b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "withsklearn=round(r2_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09e222b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withsklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b026c",
   "metadata": {},
   "source": [
    "# Comparitive graph for accuracy of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49ccf496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "no_hypertuned = withoutsklearn\n",
    "with_library = withsklearn\n",
    "\n",
    "plt.bar([\"Model witout sklearn\", \"Model with sklearn\"], [no_hypertuned, with_library])\n",
    "\n",
    "plt.text(0, no_hypertuned + 0.01, str(no_hypertuned))\n",
    "plt.text(1, with_library + 0.01, str(with_library))\n",
    "\n",
    "plt.ylim(0, 0.9)\n",
    "\n",
    "plt.xlabel(\"Model Names\")\n",
    "plt.ylabel(\"R2 Scores of Models\")\n",
    "plt.title(\"Comparison between R2 Score of Models\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1358e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
