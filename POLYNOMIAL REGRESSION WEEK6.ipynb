{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3183c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from random import seed\n",
    "from random import randrange\n",
    "# importing StandardScaler library        \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88fe1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegression:\n",
    "    def __init__(self, degree=2, lr=0.001, n_iters=1000):\n",
    "        self.degree = degree\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.scaler = None\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # Add polynomial features\n",
    "        X_poly = self._polynomial_features(X, self.degree)\n",
    "\n",
    "        # Normalize data\n",
    "        self.scaler = StandardScaler()\n",
    "        X_poly = self.scaler.fit_transform(X_poly)\n",
    "\n",
    "        n_samples, n_features = X_poly.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = np.dot(X_poly, self.weights) + self.bias\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X_poly.T, (y_pred - y))\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights = self.weights - self.lr * dw\n",
    "            self.bias = self.bias - self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add polynomial features\n",
    "        X_poly = self._polynomial_features(X, self.degree)\n",
    "\n",
    "        # Normalize data\n",
    "        X_poly = self.scaler.transform(X_poly)\n",
    "\n",
    "        y_pred = np.dot(X_poly, self.weights) + self.bias\n",
    "        return y_pred\n",
    "\n",
    "    def _polynomial_features(self, X, degree):\n",
    "        n_samples, n_features = X.shape\n",
    "        X_poly = np.ones((n_samples, 1))\n",
    "\n",
    "        for d in range(1, degree+1):\n",
    "            for i in range(n_features):\n",
    "                X_poly = np.concatenate((X_poly, (X[:,i]**d).reshape(-1,1)), axis=1)\n",
    "\n",
    "        return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1806a4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SPOORTHY\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#d = datasets.load_boston()\n",
    "#x, y = d.data, d.target\n",
    "\n",
    "# Load Boston dataset\n",
    "boston = datasets.load_boston()\n",
    "X, y = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1139c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4e3e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model and make predictions\n",
    "reg = PolynomialRegression(degree=2, lr=0.1, n_iters=1000)\n",
    "reg.fit(X_train, y_train)\n",
    "predictions = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e45e1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.8536406806101907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "r2score = r2_score(y_test, predictions)\n",
    "print('R2 score:', r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee9b1ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SPOORTHY\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\SPOORTHY\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\SPOORTHY\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: (0.001, 1000, 2)\n",
      "Validation r2score: 0.8536406806101907\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# define hyperparameters to tune\n",
    "lr = [0.001, 0.1, 0.5]\n",
    "n_iters = [1000, 5000, 10000]\n",
    "degree = [2, 3]\n",
    "\n",
    "# create all possible combinations of hyperparameters\n",
    "hyperparameters = list(product(lr, n_iters,degree))\n",
    "\n",
    "# initialize best accuracy and corresponding hyperparameters\n",
    "best_r2score = 0\n",
    "best_hyperparameters = None\n",
    "\n",
    "# loop over all hyperparameters\n",
    "for hyperparameter in hyperparameters:\n",
    "    # create a new instance of LinearRegression with the current hyperparameters\n",
    "    lr = PolynomialRegression(lr=hyperparameter[0], n_iters=hyperparameter[1], degree=hyperparameter[2])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1234)\n",
    "    \n",
    "    # fit the model\n",
    "    lr.fit(X_train, y_train)\n",
    " \n",
    "    \n",
    "    # evaluate the model on the validation set\n",
    "    y_pred = lr.predict(X_test)\n",
    "    r2score=r2_score(y_test, predictions)\n",
    "    \n",
    "    # update best accuracy and corresponding hyperparameters\n",
    "    if r2score > best_r2score:\n",
    "        best_r2score= r2score\n",
    "        best_hyperparameters = hyperparameter\n",
    "        \n",
    "# print the best hyperparameters and corresponding accuracy\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)\n",
    "print(\"Validation r2score:\", best_r2score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3bd7f",
   "metadata": {},
   "source": [
    "# Model using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a94b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbaff89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('HousingData.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3f8d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       20\n",
       "ZN         20\n",
       "INDUS      20\n",
       "CHAS       20\n",
       "NOX         0\n",
       "RM          0\n",
       "AGE        20\n",
       "DIS         0\n",
       "RAD         0\n",
       "TAX         0\n",
       "PTRATIO     0\n",
       "B           0\n",
       "LSTAT      20\n",
       "MEDV        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a423b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>11.43</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>11.43</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>76.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  76.8  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90  11.43  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99  11.43  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(df.median())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "190f6d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa9cdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 4)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(np.c_[df['LSTAT'], df['RM'], df['CRIM'], df['NOX']], columns=['LSTAT', 'RM', 'CRIM', 'NOX'])\n",
    "Y = df['MEDV']\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0018dd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 4)\n",
      "(127, 4)\n",
      "(379,)\n",
      "(127,)\n"
     ]
    }
   ],
   "source": [
    "# splits the training and test data set in 75% : 25%\n",
    "# assign random_state to any value.This ensures consistency.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c2053bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression coefficients: [-0.56649976  5.35239531 -0.13861706 -0.60246748]\n",
      "Linear Regression intercept: -3.1562012904885073\n"
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "print('Linear Regression coefficients: {}'.format(lm.coef_))\n",
    "print('Linear Regression intercept: {}'.format(lm.intercept_))\n",
    "\n",
    "# model evaluation for training set\n",
    "y_train_predict = lm.predict(X_train)\n",
    "\n",
    "# plt.plot(np.unique(Y_train), np.poly1d(np.polyfit(Y_train, y_train_predict, 1))(np.unique(Y_train)), \n",
    "#         linewidth=2, color='r')\n",
    "\n",
    "# calculating the intercept and slope for the regression line\n",
    "b, m = np.polynomial.polynomial.polyfit(Y_train, y_train_predict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ca14780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The linear model performance for training set\n",
      "RMSE is 5.542915517308062\n",
      "R2 score is 0.6384156083074264\n"
     ]
    }
   ],
   "source": [
    "rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
    "r2 = r2_score(Y_train, y_train_predict)\n",
    " \n",
    "print(\"The linear model performance for training set\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22203e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation for testing set\n",
    "y_test_predict = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "880da3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The linear model performance for testing set\n",
      "RMSE is 5.529966534806872\n",
      "R2 score is 0.6295124547192936\n"
     ]
    }
   ],
   "source": [
    "# root mean square error of the model\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    " \n",
    "# r-squared score of the model\n",
    "r2 = r2_score(Y_test, y_test_predict)\n",
    "\n",
    "print(\"\\nThe linear model performance for testing set\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34760e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Creates a polynomial regression model for the given degree\"\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "   \n",
    "# transform the features to higher degree features.\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "   \n",
    "# fit the transformed features to Linear Regression\n",
    "poly_model = LinearRegression()\n",
    "\n",
    "poly_model.fit(X_train_poly, Y_train)\n",
    "     \n",
    "# predicting on training data-set\n",
    "y_train_predicted = poly_model.predict(X_train_poly)\n",
    "   \n",
    "# predicting on test data-set\n",
    "y_test_predicted = poly_model.predict(poly_features.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cb49985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The polynomial model performance for the training set\n",
      "RMSE of training set is 4.248274588206092\n",
      "R2 score of training set is 0.7875981397531204\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model on training data-set\n",
    "rmse_train = np.sqrt(mean_squared_error(Y_train, y_train_predicted))\n",
    "r2_train = r2_score(Y_train, y_train_predicted)\n",
    "     \n",
    "print(\"The polynomial model performance for the training set\")\n",
    "print(\"RMSE of training set is {}\".format(rmse_train))\n",
    "print(\"R2 score of training set is {}\".format(r2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fcb65b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The polynomial model performance for the test set\n",
      "RMSE of test set is 4.166238351476659\n",
      "R2 score of test set is 0.7897108665470435\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model on test data-set\n",
    "rmse_test = np.sqrt(mean_squared_error(Y_test, y_test_predicted))\n",
    "r2_test = r2_score(Y_test, y_test_predicted)\n",
    "\n",
    "print(\"The polynomial model performance for the test set\")\n",
    "print(\"RMSE of test set is {}\".format(rmse_test))\n",
    "print(\"R2 score of test set is {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b026c",
   "metadata": {},
   "source": [
    "# Comparitive graph for accuracy of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a17a0809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the accuracy scores for two different models\n",
    "model_names = ['model without sklearn', 'model with sklearn']\n",
    "accuracy_scores = [0.8536406806101907, 0.7897108665470502]\n",
    "\n",
    "# Create a bar chart of the accuracy scores\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(model_names, accuracy_scores)\n",
    "\n",
    "# Set the chart title and labels\n",
    "ax.set_title('Model Accuracy Comparison')\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Accuracy')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dd5417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
